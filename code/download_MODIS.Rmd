---
title: "Acquiring EO datasets for eLTER+ sites"
author:
  - name: Micha Silver
  - name: Arnon Karnieli
date: "20/02/2021"
output:
  github_document:
    toc: true
    toc_depth: 2
  pdf_document:
    toc: TRUE
    toc_depth: 2
bibliography: bibliography.bib  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup
Load necessary R libraries, user configurable directories, then read in the `functions.R` script with contains helper functions for summarizing layers by date and site, and plotting graphs.

### Libraries

```{r libraries, message=FALSE, results='hide', warning=FALSE}
pkg_list = c("MODIStsp", "lubridate", "raster", "ggplot2",
             "cowplot", "tidyr", "sf", "stars", "leaflet",
             "shiny","shinydashboard","shinyFiles",
             "shinyalert",  "rappdirs","shinyjs", "leafem",
             "mapedit", "magrittr")
installed_packages <- pkg_list %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(pkg_list[!installed_packages])
}
# Packages loading
pkgs = lapply(pkg_list, library, character.only = TRUE)
```

### Define directories

This code chunk includes reading a text file "site_shapefiles_url.txt"
that includes a list of sites, with three columns:
name, full_name, url
The URL is a link to the boundary shapefile from DEIMS for each site.

```{r directories}
# Edit below as necessary: GIS, output, and figures directories
# and read options and sites files
GIS_dir = "../GIS"
if (!dir.exists(GIS_dir)) {dir.create(GIS_dir,
                                      recursive = TRUE)}

# Where to save outputs
Output_dir = "../Output"
if (!dir.exists(Output_dir)) {dir.create(Output_dir,
                                         recursive = TRUE)}

# Where to save figures
Figures_dir = "../Figures"
if (!dir.exists(Figures_dir)) {dir.create(Figures_dir,
                                         recursive = TRUE)}

# List of eLTER+ sites and DEIMS URL's for download
site_list_file = "site_shapefiles_url.txt"
site_list = read.csv(site_list_file)
sites = site_list$site_name

# (Add option to ignore Datum unknown warnings)
options("rgdal_show_exportToProj4_warnings"="none")

# Load some helper functions
source("functions.R")
```

### Load polygons from DEIMS site

Download shapefiles from list of eLTER sites
Save each as geopackage
The list of sites and download URL is in: "site_shapefiles_url.txt"

```{r site-polygons, results='hide', message=FALSE, include=FALSE}
# Call ObtainSitePolygons function (in functions.R)
ObtainSitePolygons(site_list_file)
```

\newpage

## MODIS products, layers
Use the MODIStsp package to filter and download layers
@busetto_modistsp

Display lists of all available products and layers in each product category.

```{r MODIS-products, eval=FALSE}
MODIStsp_get_prodnames()
# [105] "Vegetation Indexes_16Days_250m (M*D13Q1)"
# [23] "LST_3band_emissivity_8day_1km (M*D21A2)"
# ... many more
```


```{r MODIS-layers, eval=FALSE}
MODIStsp_get_prodlayers("Vegetation Indexes_16Days_250m (M*D13Q1)")
MODIStsp_get_prodlayers("LST_3band_emissivity_8day_1km (M*D21A2)")
```

### Use the GUI
Here the user can choose:
 
 * product, layers
 * start and end dates
 * a polygon area of interest (shapefile or Geopackage)
 * and satellite platforms
 * Each set of options saved to *.json file
 
Requires registration on EarthData website:
https://urs.earthdata.nasa.gov/home
 
Example:
In **"Products and Layers"** panel
  * from Product Category dropdown
    - choose Ecosystem variables Vegetation Indices
  * from Product Name dropdown
    - choose Vegetation_Indices_16days_250m
  * from layers to be processed dropdown
    - choose 16 day NDVI average
  * from Platform
    - choose Both
 
In **"Spatial Temporal"** panel
  * in Temporal Range, select date range
  * in Output Projection
    - select User defined
    - click "Change" and enter EPSG for desired projection
    - i.e. 3035 for ETRS89 based European LAEA (conformal) projection
  * in Spatial Extent choose "Load from Spatial file" and click browse to choose gpkg for site 
  
In **Output Format**
  * Under Download Method, enter username and password
  * Under Output Options, choose R rasterStack
  * Under Output Folders, click browse to select output location
 
Click **Save Options** 
  * Save as json file
  * Browse to save under R code directory
  
```{r GUI}
MODIStsp()
```

### Loop over all sites
Call the MODIStsp() function with `gui = FALSE` and point to each json formatted options file to run the download. The options file was saved from the GUI step above. This loop downloads all available MODIS tiles for each AOI.

The download utility used here is "aria2". It can be obtained from:
https://github.com/aria2/aria2/releases/tag/release-1.35.0

You **must supply a username and password** for authentication on the EarthData website

This code block will run for a **long** time.

```{r loop-sites, eval=FALSE}
#---------------------------------
# Enter username and password here for EarthData website
user = 'your user name'
password = 'your password'
#---------------------------------
config_files = list.files(".", pattern = ".json$",
                          full.names = TRUE)
spatial_files = list.files(GIS_dir, pattern = ".gpkg$",
                           full.names = TRUE)

# Loop over sites
lapply(spatial_files, FUN = function(site) {
   t0 = Sys.time()
   site_name = basename(tools::file_path_sans_ext(site))
   print(paste(t0, "-- Processing site:", site_name))
   # Loop over configurations   
   lapply(config_files, FUN = function(cfg) {
     MODIStsp(gui = FALSE,
            opts_file = cfg,
            spafile = site,
            spameth = "file",
            user = user,
            password = password,
            #start_date = "2018.10.01", # To change the dates
            #sensor = "Aqua",  # "Terra" or "Both"
            downloader = "aria2", # "html" or "aria2" if it is installed
            verbose = FALSE
            )
   })
   t1 = Sys.time()
   elapsed = round(difftime(t1, t0, units = "mins"))
   print(paste(t0, "-- Completed site:", site_name,
               "in", elapsed, "mins"))
 })

```

\newpage

## Time series EO products averaged for each site
Loop over all sites and summarize pixels by date for each site.
The functions used here are stored in `functions.R`

### Site timeseries data
```{r timeseries-averages, warning=FALSE}
# Call TimeSeriesFromRaster() function for each site
# Create graphs of each time series with PlotTimeSeries() function
for (site in sites){
  t0 = Sys.time()
  print(paste(t0, "-- Time series for site:", site))
  timeseries_list = TimeSeriesFromRasters(site)
  PlotTimeSeries(timeseries_list, site)
}
```


### Corine Landcover for four years of CLC rasters
Corine Landcover rasters at 100 m resolution, for four years.
Have been downloaded in advance from:
https://land.copernicus.eu/pan-european/corine-land-cover
Crop each raster to extent of the site bounding box

```{r CLC-landcover}
# Crop Corine Landcover from four years for each site
# Call CropSaveCorine() function for each site

for (site in sites) {
   CropSaveCorine(site)
}
````

