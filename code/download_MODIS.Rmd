---
title: "Acquiring EO datasets for eLTER+ sites"
author:
  - name: Micha Silver
  - name: Arnon Karnieli
date: "20/02/2021"
output:
  github_document:
    toc: true
    toc_depth: 2
  pdf_document:
    toc: TRUE
    toc_depth: 2
bibliography: bibliography.bib  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup
Load necessary R libraries, user configurable directories, then read in the `functions.R` script with contains helper functions for summarizing layers by date and site, and plotting graphs.
```{r libraries}
pkg_list = c("MODIStsp", "lubridate", "raster", "ggplot2",
             "tidyr", "sf", "stars", "exactextractr", "leaflet",
             "shiny","shinydashboard","shinyFiles", "shinyalert", 
             "rappdirs","shinyjs", "leafem", "mapedit", "magrittr")
installed_packages <- pkg_list %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(pkg_list[!installed_packages])
}
# Packages loading
lapply(pkg_list, library, character.only = TRUE)
```
### Define directories
```{r directories}
# Edit below as necessary: GIS directory, output directory and options files
GIS_dir = "../GIS"
if (!dir.exists(GIS_dir)) {dir.create(GIS_dir,
                                      recursive = TRUE)}

# Where to save outputs
Output_dir = "../Output"
if (!dir.exists(Output_dir)) {dir.create(Output_dir,
                                         recursive = TRUE)}

# Load some helper functions
source("functions.R")
```

### Load polygons from DEIMS site
```{r site_polygons, results='hide', message=FALSE}
# Download shapefiles from list of eLTER sites
# Save as geopackage
# The list of sites and download URL is in:
# "site_shapefiles_url.txt"
# Call ObtainSitePolygons function (in functions.R)
site_list_file = "site_shapefiles_url.txt"
sites_sf = ObtainSitePolygons(site_list_file)
```

\newpage

## MODIS products, layers
Use the MODIStsp package to filter and download layers
@busetto_modistsp

Display lists of all available products and layers in each product category.

```{r MODIS products}
MODIStsp_get_prodnames()
# [105] "Vegetation Indexes_16Days_250m (M*D13Q1)"
# [23] "LST_3band_emissivity_8day_1km (M*D21A2)"
```


```{r MODIS layers}
MODIStsp_get_prodlayers("Vegetation Indexes_16Days_250m (M*D13Q1)")
MODIStsp_get_prodlayers("LST_3band_emissivity_8day_1km (M*D21A2)")
```

### Use the GUI
Here the user can choose:
 
 * product, layers
 * start and end dates
 * a polygon area of interest (shapefile or Geopackage)
 * and satellite platforms
 * Each set of options saved to *.json file
 
Requires registration on EarthData website:
https://urs.earthdata.nasa.gov/home
 
Example:
In **"Products and Layers"** panel
  * from Product Category dropdown
    - choose Ecosystem variables Vegetation Indices
  * from Product Name dropdown
    - choose Vegetation_Indices_16days_250m
  * from layers to be processed dropdown
    - choose 16 day NDVI average
 
In **"Spatial Temporal"** panel
  * in Temporal Range, select date range
  * in Output Projection
    - select User defined
    - click "Change" and enter EPSG for desired projection
    - i.e. 3035 for ETRS89 based European LAEA (conformal) projection
  * in Spatial Extent choose "Load from Spatial file" and click browse to choose gpkg for site 
  
In **Output Format**
  * Under Download Method, enter username and password
  * Under Output Options, choose R rasterStack
  * Under Output Folders, click browse to select output location
 
Click **Save Options** 
  * Save as json file
  * Browse to save under R code directory
  
```{r GUI}
MODIStsp()
```

### Loop over all sites
Call the MODIStsp() function with `gui = FALSE` and point to each json formatted options file to run the download. The options file was saved from the GUI step above. This loop downloads all available MODIS tiles for each AOI.

The download utility used here is "aria2". It can be obtained from:
https://github.com/aria2/aria2/releases/tag/release-1.35.0

You **must supply a username and password** for authentication

```{r loop_sites, results='hide'}
#---------------------------------
# Enter username and password here for EarthData website
user = 'your user name'
password = 'your password'
#---------------------------------
config_files = list.files(".", pattern = ".json$",
                          full.names = TRUE)
spatial_files = list.files(GIS_dir, pattern = ".gpkg$",
                           full.names = TRUE)

# Loop over sites
lapply(spatial_files, FUN = function(site) {
   t0 = Sys.time()
   site_name = basename(tools::file_path_sans_ext(site))
   print(paste(t1, "-- Processing site:", site_name))
   # Loop over configurations   
   lapply(config_files, FUN = function(cfg) {
     MODIStsp(gui = FALSE,
            opts_file = cfg,
            spafile = site,
            spameth = "file",
            user = user,
            password = password,
            #start_date = "2018.10.01", # To change the dates
            #sensor = "Aqua",  # "Terra" or "Both"
            downloader = "aria2", # "html" or "aria2" if it is installed
            verbose = FALSE
            )
   })
 })

```

\newpage

## Time series EO products averaged for each site
Loop over all sites and summarize pixels by date for each site.
The functions used here are stored in `functions.R`

### Vegetation indices
```{r vi_pixel_averages}
# site_names = lapply(site_files, FUN = function(f) {
#                       tools::file_path_sans_ext(basename(f))})
# 
# lapply(1:length(site_names), FUN = function(s) {
#   # Get site polygon as sf object
#   site_name = site_names[[s]]
#   site = read_sf(site_files[s])
#   
#   # Extract NDVI and EVI time series, and plot
#   VI_folder = file.path(Output_dir, site_name,
#                         "VI_16Days_250m_v6")
#   # NDVI
#   mod_stars = StarsFromFolder(VI_folder, site, "NDVI")
#   NDVI_df = ValuesFromStars(mod_stars, "NDVI")
#   date_df = DatesFromFolder(file.path(VI_folder, "NDVI"))
#   #cnt_df = PixelCountFromStars(mod_stars)
#   cnt_df = PixelCountFromFolder(
#     file.path(VI_folder, "NDVI"), site)
#   # EVI
#   mod_stars = StarsFromFolder(VI_folder, site, "EVI")
#   EVI_df = ValuesFromStars(mod_stars, "EVI")
#   VI_df = cbind(date_df, NDVI_df, EVI_df, cnt_df)
#   PlotSave(site_name, VI_df, "VI")
# })
```

### Land surface temperature
```{r lst_pixel_averages}
# site_names = lapply(site_files, FUN = function(f) {
#                       tools::file_path_sans_ext(basename(f))})
# 
# lapply(1:length(site_names), FUN = function(s) {
#   # Extract LST day and night time series, and plot
#   LST_folder = file.path(Output_dir, site_name,
#                          "LST_3band_emissivity_8day_1km")
#   # Day
#   mod_stars = StarsFromFolder(LST_folder, site, "LST_Day_1KM")
#   LST_day = ValuesFromStars(mod_stars, "LST_Day_1KM")
#   date_df = DatesFromFolder(file.path(LST_folder, "LST_Day_1KM"))
#   # cnt_df = PixelCountFromStars(mod_stars)
#   cnt_df = PixelCountFromFolder(
#     file.path(LST_folder, "LST_Day_1KM"), site)
#   # Night
#   mod_stars = StarsFromFolder(LST_folder, site, "LST_Night_1KM")
#   LST_night = ValuesFromStars(mod_stars, "LST_Night_1KM")
# 
#   LST_df = cbind(date_df, LST_day, LST_night, cnt_df)
#   PlotSave(site_name, LST_df, "LST")
# })
# ```
# 
```

#### Corine Landcover for four years of CLC rasters
```{r landcover}
# ## Crop Corine Landcover from four years for each site
# ```{r corine_landcover}
# corine_basedir = "/home/micha/GIS/Corine_CLC"
# corine_datadirs = list.dirs(path = corine_basedir)
# corine_datadirs = corine_datadirs[grepl(pattern = "DATA$", x = corine_datadirs)]
# corine_list = sapply(corine_datadirs, 
#                      FUN = function(d) {list.files(d,
#                                                    pattern = ".*tif$",
#                                                    full.names = TRUE)},
#                      USE.NAMES = FALSE)
# site_names = lapply(site_files, FUN = function(f) {
#                       tools::file_path_sans_ext(basename(f))})
# 
# for (s in 1:length(site_names)) {
#   site_name = site_names[[s]]
#   site = read_sf(site_files[s])
#   # Transform site boundary to LAEA ETRS89 to match Corine data
#   site = st_transform(site, crs=3035)
#   for (clc_path in corine_list) {
#       clc = read_stars(clc_path)
#       CropSaveCorine(clc, clc_path, site, site_name)
#   }
# }
````

